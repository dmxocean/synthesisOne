{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import difflib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.width\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to the CSV files\n",
    "data_path = \"../data/raw/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV data into a pandas DataFrame\n",
    "try: \n",
    "    clients_df = pd.read_csv(os.path.join(data_path, \"clients.csv\"))\n",
    "    sample_df = pd.read_csv(os.path.join(data_path, \"sample.csv\"))\n",
    "    schedules_df = pd.read_csv(os.path.join(data_path, \"schedules.csv\"))\n",
    "    translators_df = pd.read_csv(os.path.join(data_path, \"translatorsCostPairs.csv\"))\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File not found: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CSV Client Data\")\n",
    "display(clients_df.head())\n",
    "\n",
    "print(\"CSV Sample Data\")\n",
    "display(sample_df.head())\n",
    "\n",
    "print(\"CSV Schedules Data\")\n",
    "display(schedules_df.head())\n",
    "\n",
    "print(\"CSV Translators Data\")\n",
    "display(translators_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples_df = {\n",
    "    \"Clients\": clients_df,\n",
    "    \"Sample\": sample_df,\n",
    "    \"Schedules\": schedules_df,\n",
    "    \"Translators\": translators_df\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MISSING VALUES\", \"\\n\")\n",
    "\n",
    "for name, df in tuples_df.items():\n",
    "    print(f\"{name} Dataset\")\n",
    "    print(f\"\\t{df.isnull().sum().sum()} missing values\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DUPLICATED VALUES\", \"\\n\")\n",
    "\n",
    "for name, df in tuples_df.items():\n",
    "    print(f\"{name} Dataset\")\n",
    "    print(f\"\\t{df.duplicated().sum()} duplicated values\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"UNIQUE VALUES\", \"\\n\")\n",
    "\n",
    "for name, df in tuples_df.items():\n",
    "    print(f\"{name} Dataset\")\n",
    "    print(f\"\\tUnique Values:\")\n",
    "    for col in df.columns:\n",
    "        print(f\"\\t\\t{col}: {df[col].nunique()}\")    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DATASETS\", \"\\n\")\n",
    "\n",
    "for name, df in tuples_df.items():\n",
    "    print(f\"{name} Dataset\")\n",
    "    print(f\"\\t{df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "    print(f\"\\tData Types:\")\n",
    "    for col, dtype in df.dtypes.items():\n",
    "        print(f\"\\t\\t{col}: {dtype}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_values(df):\n",
    "    \"\"\"\n",
    "    Get unique values for each column in a DataFrame\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame to get unique values from\n",
    "\n",
    "    Returns:\n",
    "    dict: Unique values for each column\n",
    "    \"\"\"\n",
    "\n",
    "    unique_values = {}\n",
    "    for col in df.columns:\n",
    "        unique_values[col] = df[col].unique()\n",
    "    return unique_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_useful = {\n",
    "    \"Clients\": [\"CLIENT_NAME\", \"WILDCARD\"],\n",
    "    \"Sample\": [\n",
    "        \"TASK_TYPE\",\n",
    "        \"SOURCE_LANG\",\n",
    "        \"TARGET_LANG\",\n",
    "        \"TRANSLATOR\",\n",
    "        \"MANUFACTURER\",\n",
    "        \"MANUFACTURER_SECTOR\",\n",
    "        \"MANUFACTURER_INDUSTRY_GROUP\",\n",
    "        \"MANUFACTURER_INDUSTRY\",\n",
    "        \"MANUFACTURER_SUBINDUSTRY\",\n",
    "    ],\n",
    "    \"Schedules\": [\"NAME\"],\n",
    "    \"Translators\": [\"TRANSLATOR\", \"SOURCE_LANG\", \"TARGET_LANG\", \"HOURLY_RATE\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"UNIQUE VALUES\")\n",
    "print()\n",
    "\n",
    "# Unique values for each column in each DataFrame\n",
    "unique_values = {}\n",
    "\n",
    "for name, df in tuples_df.items():\n",
    "    unique_values[name] = get_unique_values(df[cols_useful[name]])   \n",
    "\n",
    "for name, values in unique_values.items():\n",
    "    print(f\"{name} Dataset\")\n",
    "    for col, unique_vals in values.items():\n",
    "        display(pd.DataFrame({col: unique_vals}))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSV Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of unique clients: {clients_df['CLIENT_NAME'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution - Selling prices & Minimum quality requirements\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(clients_df[\"SELLING_HOURLY_PRICE\"], kde=True)\n",
    "plt.title(\"Distribution of Selling Hourly Prices\")\n",
    "plt.xlabel(\"Price\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(clients_df[\"MIN_QUALITY\"], kde=True)\n",
    "plt.title(\"Distribution of Minimum Quality Requirements\")\n",
    "plt.xlabel(\"Minimum Quality\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze relationship - Selling price & Minimum quality\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=\"MIN_QUALITY\", y=\"SELLING_HOURLY_PRICE\", data=clients_df)\n",
    "plt.title(\"Relationship between Minimum Quality and Selling Price\")\n",
    "plt.xlabel(\"Minimum Quality\")\n",
    "plt.ylabel(\"Selling Hourly Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSV Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse dates\n",
    "if schedules_df[\"START\"].dtype == \"object\":\n",
    "    schedules_df[\"START\"] = pd.to_datetime(schedules_df[\"START\"], errors=\"coerce\")\n",
    "    schedules_df[\"END\"] = pd.to_datetime(schedules_df[\"END\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Basic information:\")\n",
    "schedules_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Statistical summary:\")\n",
    "display(schedules_df.describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CSV Schedules Data\")\n",
    "display(schedules_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Fix this error in preprocessing step\n",
    "\n",
    "# Duration in hours for each row\n",
    "schedules_df[\"HOURS\"] = (schedules_df[\"END\"] - schedules_df[\"START\"]).dt.total_seconds() / 3600\n",
    "\n",
    "# Group by NAME and sum the hours\n",
    "total_hours_per_name = schedules_df.groupby(\"NAME\")[\"HOURS\"].sum().reset_index()\n",
    "\n",
    "\n",
    "# Obtain ONLY\n",
    "negative_hours = total_hours_per_name[total_hours_per_name[\"HOURS\"] < 0]\n",
    "\n",
    "\n",
    "print(\"Total Hours Per Name:\")\n",
    "display(total_hours_per_name)\n",
    "\n",
    "if not negative_hours.empty:\n",
    "    print(\"Names with Negative Hours (Incorrect Data):\")\n",
    "    display(negative_hours)\n",
    "else:\n",
    "    print(\"No negative hours detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Overworking hours...\n",
    "\n",
    "# Calculate weekday and weekend hours directly\n",
    "weekday_hours = schedules_df[[\"MON\", \"TUES\", \"WED\", \"THURS\", \"FRI\"]].sum(axis=1)\n",
    "weekend_hours = schedules_df[[\"SAT\", \"SUN\"]].sum(axis=1)\n",
    "\n",
    "# Create a heatmap of weekday vs weekend hours\n",
    "heatmap_data, x_edges, y_edges = np.histogram2d(weekday_hours, weekend_hours, bins=(6, 3))\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(heatmap_data.T, origin=\"lower\", cmap=\"YlGnBu\", aspect=\"auto\",\n",
    "           extent=[x_edges[0], x_edges[-1], y_edges[0], y_edges[-1]])\n",
    "plt.colorbar(label=\"Frequency\")\n",
    "plt.title(\"Heatmap of Weekday vs Weekend Availability\")\n",
    "plt.xlabel(\"Weekday Hours\")\n",
    "plt.ylabel(\"Weekend Hours\")\n",
    "plt.xticks(range(int(x_edges[0]), int(x_edges[-1]) + 1))\n",
    "plt.yticks(range(int(y_edges[0]), int(y_edges[-1]) + 1))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSV Translators Cost Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of unique translators: {translators_df['TRANSLATOR'].nunique()}\")\n",
    "print(f\"Number of source languages: {translators_df['SOURCE_LANG'].nunique()}\")\n",
    "print(f\"Number of target languages: {translators_df['TARGET_LANG'].nunique()}\")\n",
    "print(f\"Number of unique language pairs: {translators_df.groupby(['SOURCE_LANG', 'TARGET_LANG']).ngroups}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSV Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Basic information:\")\n",
    "sample_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values by column:\")\n",
    "print(sample_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique values for categorical columns\n",
    "categorical_cols = [\"PM\", \"TASK_TYPE\", \"SOURCE_LANG\", \"TARGET_LANG\", \n",
    "                   \"TRANSLATOR\", \"MANUFACTURER\", \"MANUFACTURER_SECTOR\",\n",
    "                   \"MANUFACTURER_INDUSTRY_GROUP\", \"MANUFACTURER_INDUSTRY\", \n",
    "                   \"MANUFACTURER_SUBINDUSTRY\"]\n",
    "\n",
    "print(\"Unique values for Categorical columns:\")\n",
    "print()\n",
    "for col in categorical_cols:\n",
    "    print(f\"{col}: {sample_df[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with possible repetitive information\n",
    "sample_df[[\"MANUFACTURER\", \"MANUFACTURER_SECTOR\", \"MANUFACTURER_INDUSTRY_GROUP\", \"MANUFACTURER_INDUSTRY\", \"MANUFACTURER_SUBINDUSTRY\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of unique projects: {sample_df['PROJECT_ID'].nunique()}\")\n",
    "print(f\"Number of unique tasks: {sample_df['TASK_ID'].nunique()}\")\n",
    "print(f\"Number of unique translators: {sample_df['TRANSLATOR'].nunique()}\")\n",
    "print(f\"Number of source languages: {sample_df['SOURCE_LANG'].nunique()}\")\n",
    "print(f\"Number of target languages: {sample_df['TARGET_LANG'].nunique()}\")\n",
    "print(f\"Number of unique task types: {sample_df['TASK_TYPE'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check distribution of quality evaluations (quality control scores)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(sample_df[\"QUALITY_EVALUATION\"].dropna(), bins=10, kde=True, alpha=0.75)\n",
    "plt.title(\"Distribution of Quality Evaluations\")\n",
    "plt.xlabel(\"Quality Score\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of hourly rates and costs\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(sample_df[\"HOURLY_RATE\"].dropna())\n",
    "plt.title(\"Distribution of Hourly Rates\")\n",
    "plt.xlabel(\"Hourly Rate\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(sample_df[\"COST\"].dropna())\n",
    "plt.title(\"Distribution of Costs\")\n",
    "plt.xlim(0, 500)\n",
    "plt.xlabel(\"Cost\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_language(lang, database):\n",
    "    \"\"\"\n",
    "    Standardize a language name to match a reference list using Levenshtein distance\n",
    "\n",
    "    Parameters:\n",
    "    lang (str): Language to standardize\n",
    "    database (list): List of reference language names\n",
    "\n",
    "    Returns:\n",
    "    str: Standardized language name\n",
    "    \"\"\"\n",
    "    # Lowercase the language name\n",
    "    reference_list = [x.lower() for x in database if isinstance(x, str)]\n",
    "    \n",
    "    # Levenshtein distance to get the closest match\n",
    "    closest = difflib.get_close_matches(lang.lower(), reference_list, n=1, cutoff=0)[0]\n",
    "    \n",
    "    # Get the index of the closest match and return the original case from reference_list\n",
    "    index = reference_list.index(closest)\n",
    "    \n",
    "    return database[index]\n",
    "\n",
    "# Database\n",
    "all_languages = np.sort(pd.concat([\n",
    "    sample_df[\"SOURCE_LANG\"],\n",
    "    sample_df[\"TARGET_LANG\"],\n",
    "    translators_df[\"SOURCE_LANG\"],\n",
    "    translators_df[\"TARGET_LANG\"]\n",
    "]).dropna().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Example\n",
    "new_input_lang = \"Spanish (Iberiano)\"\n",
    "\n",
    "# Standardize the language\n",
    "standardized_lang = standardize_language(new_input_lang, all_languages)\n",
    "print(standardized_lang) \n",
    "\n",
    "\n",
    "# Example using Dataframe\n",
    "new_record = pd.DataFrame([{\n",
    "    \"PROJECT_ID\": 213495,\n",
    "    \"PM\": \"JSM\",\n",
    "    \"TASK_ID\": 10048286,\n",
    "    \"START\": \"2014-11-27 09:00:00\",\n",
    "    \"END\": \"2014-11-27 13:00:00\",\n",
    "    \"TASK_TYPE\": \"Translation\",\n",
    "    \"SOURCE_LANG\": \"Spanishh (Iberian)\",\n",
    "    \"TARGET_LANG\": \"Englisasdh\",\n",
    "    \"TRANSLATOR\": \"Carlos\",\n",
    "    \"ASSIGNED\": \"2014-11-27 08:30:00\",\n",
    "    \"CLOSE\": \"2014-11-27 14:00:00\",\n",
    "    \"FORECAST\": 0.5,\n",
    "    \"HOURLY_RATE\": 30,\n",
    "    \"COST\": 15.0,\n",
    "    \"QUALITY_EVALUATION\": 8,\n",
    "    \"MANUFACTURER\": \"Global Tech\",\n",
    "    \"MANUFACTURER_SECTOR\": \"Technology\",\n",
    "    \"MANUFACTURER_INDUSTRY_GROUP\": \"Software & Services\",\n",
    "    \"MANUFACTURER_INDUSTRY\": \"IT Services\",\n",
    "    \"MANUFACTURER_SUBINDUSTRY\": \"Data Processing & Outsourced Services\"\n",
    "}])\n",
    "\n",
    "# Dataframe\n",
    "new_record_df = new_record\n",
    "\n",
    "# Display results\n",
    "display(new_record_df)\n",
    "\n",
    "new_record_df[\"SOURCE_LANG\"] = new_record_df[\"SOURCE_LANG\"].apply(standardize_language, database=all_languages)\n",
    "new_record_df[\"TARGET_LANG\"] = new_record_df[\"TARGET_LANG\"].apply(standardize_language, database=all_languages)\n",
    "\n",
    "display(new_record_df)\n",
    "\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Synthesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
